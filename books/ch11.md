- ch11 하둡 관리
    
    구축된 클러스터를 안정적으로 운영하고, 장애에 대응하며, 변화에 맞춰 진화시키는데 필요한 관리 기법 및 동작 원리
    
    ## 1 HDFS 고급 관리
    
    ### 1.1 영속적인 데이터 구조 : FsImage와 EditLog
    
    namenode는 파일시스템의 모든 메타데이터 관리한다.
    
    해당 데이터 영속성을 보장하기 위해 hdfs는 스냅샷과 저널링 방식을 결합한 구조를 사용한다.
    
    FsImage : 특정 시점의 파일시스템 네임스페이스 전체에 대한 스냅샷.
    
    EditLog : 파일 생성, 삭제, 이름 변경 등 모든 변경사항을 순차적으로 기록하는 트랜잭션 로그(저널)이다. 클라이언트의 쓰기 요청은 **먼저 editlog에 기록된 후 메모리에 반영되므로**, 네임노드 장애 발생하더라도 editlog 재생하여 마지막 트랜잭션까지 복구 가능하다.
    
    이를 통해 성능과 일관성을 동시에 확보한다.
    
    모든 변경사항을 매번 FsImage 파일에 반영하는 것은 디스크 I/O 측면에서 매우 비효율적이다. 
    대신, 가볍고 순차쓰기만 필요한 EditLog에 변경사항을 빠르게 추가하여 쓰기 성능을 극대화할 수 있다.
    
    (-) 하지만 editlog만 있다면 namenode 재시작시 모든 로그 재생해야하므로 오래 걸릴 수 있다.
    
    (sol) secondary namenode : 주기적으로 namenode로부터 최신 FsImage와 EditLog를 가져와 병합하여 새로운 FsImage를 만드는 체크포인팅 작업을 수행한다.
    
    해당 작업은 메인 namenode 부하없이 비동기적으로 이루어진다.
    
    ### 1.2 안전 모드
    
    namenode는 시작 직후 항상 안전모드로 진입한다.
    
    해당 상태에서 파일시스템은 읽기 전용으로 동작한다.
    
    이를 통해 불완전한 메타데이터 상태에서 데이터 손상을 유발할 수 있는 작업을 차단한다.
    
    ex)
    
    namenode 재시작 직후에는 어떤 데이터 블록이 어느 datanode에 존재하는지 정보가 없음. 
    
    이때 블록 삭제 요청을 허용한다면 아직 리포트를 보내지 않은 정상적인 datanode에 있는 유효한 블록을 삭제해버리는 데이터 유실이 발생할 수 있음
    
    따라서 namenode는 클러스터의 datanode들로부터 충분한 수의 블록 리포트를 수신하여, 전체 블록의 대다수(default 99.9%)가 최소 복제수(default 1)를 만족한다고 판단될 때 까지 안전모드 유지한다.
    
    ### 1.3 dfsadmin
    
    dfsadmin 도구를 통해 hdfs의 상태정보를 확인하고 다양한 관리작업을 수행할 수 있는 다목적 도구이다.
    
    그냥 명령어,,
    
    ### 1.4 파일시스템 무결성 검사 (fsck와 블록 스캐너)
    
    hdfs는 데이터 손상을 논리적 손상, 물리적 손상 두가지 유형으로 구분하여 관리한다.
    
    fsck (file system check) : namenode의 메타데이터를 기준으로 파일시스템의 논리적 무결성을 검사한다. 
    
    ex) 초과 복제 블록, 복제 기준 미만의 블록, 잘못 복제된 블록 (랙 기준 위반 등), 손상된 블록, 누락된 복제본
    
    *손상되거나 누락된 블록이 데이터가 없어짐을 의미하기 때문에 가장 큰 문제이다.
    
    데이터노드 블록 스캐너 : 각 DataNode에서 백그라운드로 실행되며, 자신이 저장하고 있는 블록 데이터의 물리적 무결성을 주기적으로 검사한다. 블록과 함께 저장된 **체크섬** 값을 비교하여 디스크의 물리적 오류등으로 인해 데이터 비트가 손상되었는지 확인한다.
    
    위 두 도구는 상호 보완적으로 작동하며, hdfs가 소프트웨어 버그로 인한 메타데이터 불일치부터 디스크 고장으로 인한 물리적 데이터 손상에 이르기까지 다양한 유형의 장애에 효과적으로 대응할 수 있도록 한다.
    
    ### 1.5 밸런서 도구
    
    밸런서는 클러스터 내 DataNode간의 디스크 사용률을 균등하게 만들기 위해서 블록을 재분배하는 도구이다.
    
    밸런서는 클러스터가 균형 상태가 될 때까지 수행된다.
    
    밸런서 실행 로그를 통해 각 반복마다 얼마나 많은 데이터가 이동했는지 확인할 수 있다.
    
    설정을 통해 대역폭 사용을 제한하여 정상적인 클러스터 운영에 미치는 영향을 최소화할 수 있도록 설계되었다. (dfs.datanode.balance.bandwidthPerSec)
    
    ## 2 클러스터 모니터링 및 유지보수
    
    ### 2.1 모니터링 전략
    
    효율적인 클러스터 운영을 위해서 시스템 상태를 지속적으로 관찰하고 문제 발생 시 신속하게 원인을 파악할 수 있는 모니터링 체계는 필수적이다.
    
    하둡은 문제 해결을 위한 다층적 접근을 제공한다.
    
    1단계 (거시적 상태 파악 - 메트릭) : 모든 하둡 데몬은 자신의 상태(ex. hdfs 사용량, yarn 컨테이너 수, jvm 힙 메모리 사용량 등)을 나타내는 수치인 메트릭을 생성하고, jmx를 통해 외부로 노출되어 prometheus 같은 표준 모니터링 도구와 연동하여 클러스터의 전반적인 건강 상태를 실시간 대시보드로 확인할 수 있다.
    
    2단계 (미시적 원인 분석 - 로그) : 대시보드에서 이상징후 (ex. 특정 datanode 응답시간 급증)가 발견되면, 해당 데몬의 로그파일을 분석하여 구체적인 오류 메시지나 경고를 찾아야한다. hadoop daemonlog 명령어 또는 웹 ui를 통해 확인 가능하다.
    
    3단계 (애플리케이션 성능 분석 - 카운터) : 클러스터는 정상이지만 특정 mapreduce 작업이 느리게 실행된다면, 해당 작업의 카운터 정보를 분석해야한다. 이를 통해 각 단계에서 처리된 레코드 수, 입출력 데이터 크기 등을 분석하여 개선해야한다.
    
    **메트릭 → 로그 → 카운터 순으로 체계적인 분석흐름 이해하는 것이 트러블슈팅 핵심**
    
    ### 2.2 백업 및 복구
    
    hdfs는 높은 내구성을 제공하지만, 운영자의 실수나 대규모 재해로부터 데이터를 보호하기 위해서는 별도의 백업 전략이 반드시 필요하다.
    
    hadoop 백업은 메타데이터와 데이터라는 두가지 축으로 이루어진다.
    
    메타데이터 백업 : 가장 중요한 백업 대상은 namenode의 메타데이터(FsImage, EditLog)이다. 정기적으로 secondary namenode의 체크포인트 디렉토리를 백업하거나, hdfs dfsadmin -fetchImage 활용
    
    *네임노드의 영속적인 메타데이터가 손실되거나 훼손되면 전체 파일시스템을 사용할 수 없게 된다.
    
    데이터 백업 : distcp(distributed copy)는 hdfs 클러스터 간에 대용량 데이터를 병렬로 복사하는 가장 효율적인 도구이다. 이를 통해 운영 클러스터의 데이터를 백업 클러스터나 클라우드 스토리지로 정기적으로 백업할 수 있다.
    
    hdfs 스냅샷 : 스냅샷은 특정 디렉토리의 특정 시점 상태를 매우 효율적으로 저장한다. 실제 데이터 복사하는 대신 포인터 사용하므로 생성 비용 거의 들지 않다. 이는 실수로 인한 데이터 삭제나 변경으로부터 빠르게 복구하거나, 특성 시점의 데이터 분석을 위해 일관된 데이터 셋을 확보하는 데 매우 유용하다.
    
    *추가
    
    파일시스템 점검(fsck) : 전체 파일시스템에서 누락되거나 손상된 블록을 사전에 찾기 위해 fsck 도구를 정기적으로 실행하는 것을 권장한다.
    
    파일 시스템 밸런서 : 파일 시스템 데이터 노드를 균등한 상태로 유지하기 위해 밸런서 도구를 정기적으로 실행하는 것을 권장한다.
    
    ### 2.3 클러스터 확장 및 축소 (유연한 운영)
    
    클러스터는 비즈니스 요구사항에 따라 유연하게 확장되거나 축소될 수 있어야 한다.
    
    이에 hadoop은 서비스 중단 없이 노드를 추가하거나 제거하는 기능을 제공한다.
    
    **노드 추가(Commissioning):** 
    
    새로운 노드를 클러스터에 추가하고 
    
    DataNode와 NodeManager 데몬을 시작한 후, 
    
    `dfs.hosts` 파일에 해당 노드의 호스트명을 추가하고 
    
    `hdfs dfsadmin -refreshNodes` 명령을 실행하면 클러스터에 포함된다.
    
    하지만 새로 추가된 노드는 데이터가 없으므로, `Balancer` 도구를 실행하여 기존 노드들의 데이터를 새 노드로 재분배해야 한다.
    
    이는 단순히 디스크 사용량을 맞추는 것이 아니라, 새로 추가된 노드에도 데이터가 고르게 분포되도록 하여 데이터 지역성(Data Locality)을 회복하고 클러스터 전체의 성능을 최적화하는 중요한 과정이다.
    
    **노드 제거(Decommissioning):** 
    
    노드를 유지보수하거나 교체하기 위해 클러스터에서 제외해야 할 경우, 
    
    해당 노드를 `dfs.hosts.exclude` 파일에 추가하고 
    
    `hdfs dfsadmin -refreshNodes`를 실행한다. 
    
    그러면 NameNode는 해당 노드를 'Decommissioning' 상태로 변경하고, 
    
    그 노드가 가진 모든 데이터 블록의 복제본을 다른 활성 노드로 안전하게 복제하기 시작한다.
    
    모든 블록의 복제가 완료되면 해당 노드는 안전하게 클러스터에서 분리된다.
    
    이 기능은 서비스 중단 없이 클러스터를 유지보수하고 업그레이드할 수 있게 해주는 핵심 메커니즘이다.
    
    ### 2.4 업그레이드
    
    계획 및 준비 : 업그레이드 전제조건은 건강한 파일시스템, 완전한 메타데이터 백업, 임시 파일 정리이다. 추가로 api,데이터 등의 호환성을 고려해야한다.
    
    **업그레이드 프로세스:**
    
    1. 이전에 완료되지 않은 업그레이드가 있다면 마무리한다.
    2. 모든 서비스를 종료한다 (yarn → hdfs 순)
    3. namenode 메타데이터 디렉터리의 최종 백업 수행한다.
    4. 클러스터 전체에 새로운 Hadoop 소프트웨어 바이너리 설치한다.
    5. -update 플래그와 함께 hdfs 시작한다. [start-dfs.sh](http://start-dfs.sh) -upgrade.
        
        해당 명령은 namenode와 datanode가 디스크상의 데이터 구조를 새로운 layoutVersion으로 변환하도록 트리거하며, 이전 버전은 previous/ 하위 디렉터리에 보존된다.
        
    
    **업그레이드 후 결정**
    
    - 롤백기간 : 업그레이드 후 클러스터는 특별한 상태에 놓이게된다. 심각한 문제가 발견되면 롤백이 가능하다. -rollback과 함께 시작하여 수행되며, 노드들이 새로운 스토리지 형식을 버리고 previous/ 디렉터리로 돌아가게한다.
    
    *파일시스템을 업그레이드 이전 상태로 되돌리므로, 업그레이드 이후에 작성된 모든 데이터는 손실된다.
    
    - 업그레이드 완료 : 새 버전이 안정적이라고 판단되면 hdfs dfsadmin -finalizeUpgrade 명령으로 업그레이드를 완료해야한다. 이는 previous/ 디렉터리 삭제하고 클러스터를 새 버전에 완전히 커밋하는 되돌릴 수 없는 작업이다.
    
    *추가로 현재 업그레이드가 완료되기 전에는 다른 업그레이드를 수행할 수 없다.
