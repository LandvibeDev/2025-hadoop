이번 Chapter는 아래와 같은 맵리듀스 고급 기능에 대해 소개하는 절이다. 

-   카운터
-   정렬
-   조인
-   사이드 데이터 분배
-   맵리듀스 라이브러리 클래스

그렇다면....

_지금까지 우리가 알아본 맵리듀스의 기본 기능에는 무엇이 있으며,,,_

_왜 이것만으로는 부족하고 고급 기능이 필요한지 고민해보자 ... !!!_

#### 맵리듀스 기본 기능

[##_Image|kage@cdtr9O/btsPPBWXvGU/AAAAAAAAAAAAAAAAAAAAALfafQciaMjBN2gWCK03d0pS4ezqoey4mIm_9fFSYBc9/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=N7YlI1SAHWzsAzks1LbRHQqgAok%3D|CDM|1.3|{"originWidth":1146,"originHeight":348,"style":"alignCenter","width":652,"height":198}_##]

1.  HDFS에 데이터를 블록 단위로 나눠서 여러 노드에 저장. (data locality)
2.  Map : key-value형태로 데이터를 변환 후 필터링/매핑/전처리 수행
3.  Shuffle & Sort : 동일한 키를 가진 데이터끼리 한 Reduce 노드로 전달 (키 기준 오름차순 정렬)
4.  Reduce : 동일 키를 가진 값들을 집계/합산/평균/통계 계산
5.  최종 결과를 HDFS에 저장

\---------------------------------------------------_?...어떤 기능을 더 원할까...?-------------------------------------------------_

1.  _기존에는 결과 파일만 생성하잖아.. 대규모 데이터 작업 도중에 통계를 어떻게 알 수 있어...?_  
    _중간 단계에서 품질 상태나 데이터 특성을 집계 하고 싶어....._   
    **\=> Counter : UI 에서 실시간 확인 가능. 디버깅/모니터링에 용이 (내장/사용자 정의)**
2.  _키 기준 오름차순 정렬 하기 싫어~~~!!!_   
    _값 기준 정렬, 다중 키 정렬 할거야 !!!_  
    **\=> Sorting : 부분 정렬 / 전체 정렬/ 2차 정렬**
3.  _데이터가 항상 한 파일에 모여있진 않잖아..?_  
    _다른 소스에 있는것들 합칠래..! (키 기준 결합)_  
    **\=> Join : Reduce/Map - side Join**
4.  _맵 태스크가 자꾸 작은 데이터 네트워크로 참조할려고 하는데.. 느려!!!_  
    _외부 스토리지에 있는 데이터를 미리 모든 노드 로컬에 복사해 빠르게 조회할래_   
    **\=> Distributed Cache**
5.  _음... 자주 쓰이는 코드 맨날 반복해서 칠거야..?_  
    **\=> 맵리듀스 라이브러리 클래스 사용하자 !!**

고럼 이제 하나씩 더 자세히 알아보자.

### Counter

> "우리는 가끔 분석 작업과는 별도로 분석하려는 데이터 자체에 대해 궁금할 때가 있다."

~_분석하려는 데이터 자체에 대해 궁금해서 분석해보는건 분석 작업에 포함이 되지 않는걸까..? 음..._~

_어쨌건, 데이터를 분석하는 과정에서 중간단계에서 계속 데이터를 확인하고 싶은 마음이 든다는건 정말 100분 공감한다...._

_ETL 작업을 하는 도중에 지속적으로 검증을 하지 않고 가다보면, 마지막에는 어디서부터 잘못되었는지 찾기 힘들기에..._

그래서.. 카운터란?

**잡에 대한 통계 정보를 수집하는 채널**  (로그를 기록하고 탐색하는것보다 훨씬 편함..!)

#### 내장 카운터

하둡이 제공하는 내장 카운터는 여러 그룹이 있으며, 해당 그룹은 아래와 같다.

-   맵리듀스 태스크 카운터
-   파일시스템 카운터
-   FileInputFormat 카운터
-   FileOutputFormat 카운터
-   잡 카운터 : 잡이 진행되며 갱신  
    \*잡 카운터를 제외한 나머지를 통틀어 내장 태스크 카운터라고 한다.

하나씩 좀 더 자세히 알아보도록 하자. 

**태스크 카운터**

-   각 태스크가 실행될 때 해당 태스크에 대한 정보를 수집한 후 잡의 모든 태스크에 대한 값을 취합하여 최종 결과를 알려줌  
    ex) MAP\_INPUT\_RECORDS : 총 입력 레코드 수 반환 (각 맵 태스크가 읽는 레코드 수 센 후 전체 집계)
-   각 태스크 시행마다 관리 및 주기적으로 애플리케이션 마스터에게 전송
-   전역적으로 수집되며, 보낼 대마다 누적된 전체 수치를 전송
-   잡 실행 도중 태스크가 실패하면 카운터는 중단
-   태스크 진행 도중에도 의미 있는 정보를 제공하는 Counter에 대해서는 웹  UI를 통해 모니터링하는것도 유용

맵 리듀스 태스크 카운터 : 스플릿 원시 바이트, 맵/컴바인/리듀스 입'출력, 디스크/CPU/메모리, 셔플 등에 관한 정보제공

그 외 : 파일 시스템에서 읽고/쓴 동작'바이트, 맵 태스크가 FileInputFormat/FileOutputFormat을 통해 읽고/쓴 바이트 수

**잡 카운터**

-   애플리케이션 마스터에 의해 유지 -> 유일하게 네트워크를 통해 카운터를 전달할 필요 없음
-   태스크 수행중 변경되는 값이 아닌 잡 수준의 통계값을 측정 
-   실행/실패한 맵/리듀스/우버 태스크 수, 전체 시간, 강제 종료된 태스크등의 정보를 제공

[##_ImageGrid|kage@vE4ps/btsPMCiBkd0/AAAAAAAAAAAAAAAAAAAAACUWpaJW3yIktqQiUhTOlh8aoo9UZmxtI3cs-mH1TEdg/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=LpNhhFdsgq8VIyT%2B9EWrbrTfPlw%3D,kage@YTiER/btsPMY6NZyX/AAAAAAAAAAAAAAAAAAAAAEvlP3ANLrGhw7fHovJU9QV_gRilvJPtzybJO7dE1IRT/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=QNv68CSMVqLmyWAEDXVJ8V3zGHI%3D,kage@qif6e/btsPOsTuWts/AAAAAAAAAAAAAAAAAAAAAJXpvrDZHyJDaC8U12s1AN_3w26JNeI2RAGx_u8gbeLu/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=Y2QlIi%2FO0lI%2B1t48dJk5ZaUXbmI%3D|data-origin-width="1120" data-origin-height="1669" data-is-animation="false" style="width: 27.7712%; margin-right: 10px;" data-widthpercent="28.43",data-origin-width="1122" data-origin-height="1386" data-is-animation="false" style="width: 33.5013%; margin-right: 10px;" data-widthpercent="34.3",data-origin-width="1096" data-origin-height="1246" data-is-animation="false" data-widthpercent="37.27" style="width: 36.402%;"|_##]

#### 사용자 정의 카운터

enum 으로 카운터 그룹을 설정, 필드는 카운터명. (전역)

```
public class MaxTemperatureWithCounters extends Configured implements Tool {

    enum Temperature {
        MISSING,
        MALFORMED
    }

    static class MaxTemperatureMapperWithCounters
            extends Mapper<LongWritable, Text, Text, IntWritable> {

        private NcdcRecordParser parser = new NcdcRecordParser();

        @Override
        protected void map(LongWritable key, Text value, Context context)
                throws IOException, InterruptedException {

            parser.parse(value);

            if (parser.isValidTemperature()) {
                int airTemperature = parser.getAirTemperature();
                context.write(new Text(parser.getYear()),
                        new IntWritable(airTemperature));

            } else if (parser.isMalformedTemperature()) {
                System.err.println("Ignoring possibly corrupt input: " + value);
                context.getCounter(Temperature.MALFORMED).increment(1);

            } else if (parser.isMissingTemperature()) {
                context.getCounter(Temperature.MISSING).increment(1);
            }

            // dynamic counter
            context.getCounter("TemperatureQuality", parser.getQuality()).increment(1);
        }
    }
}
```

[##_Image|kage@cbKEdu/btsPPCBzGdK/AAAAAAAAAAAAAAAAAAAAAJGo6cjYqq5cf09VXxqM1ACFVvIdzP6r7p2Ihz7WYXqe/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=R3V659CIvKFHZuifzCUrBBmi6E4%3D|CDM|1.3|{"originWidth":436,"originHeight":372,"style":"floatLeft","width":341,"height":291}_##]

위 코드의 출력 결과는 좌측과 같다. 

Temperature.MALFORMED

Temperature.MISSING

parser.getQuality() 

위 3가지 코드 부분에서 가져온 counter 값들이 

잘 표시되고 있는걸 확인해볼 수 있다.

위에서 TemperatureQuality를 가져오는 부분은 enum에 속해있지 않은데..? 라고 생각할 수 있다.

이를 바로 "**동적 카운터**" 라고 하며, 자바 enum 필드는 컴파일 시점에 정의되기 때문에 이와 같은 방식을 사용한다.

이렇듯 많은 카운터 값을 반환받아 확인 하는 방법에는 웹 UI, 명령행(mapred job -count)가 있는데, 자바 API로도 가능하다 ! 

잡이 안정적으로 동작중일 때는 실행 중에도 카운터 값을 얻을 수 있다!

```
Counters counters = job.getCounters();

long missing = counters.findCounter(
        MaxTemperatureWithCounters.Temperature.MISSING).getValue();

long total = counters.findCounter(TaskCounter.MAP_INPUT_RECORDS).getValue();

System.out.printf(
        "Records with missing temperature fields: %.2f%%%n",
        100.0 * missing / total
);
```

### Sorting

#### 부분 정렬

 HashPartitioner를 이용하여 IntWritable 키로 **SequenceFile**을 정렬하는 맵리듀스 프로그램을 살펴보자. 

```
public class SortByTemperatureUsingHashPartitioner extends Configured implements Tool {

    @Override
    public int run(String[] args) throws Exception {
        Job job = JobBuilder.parseInputAndOutput(this, getConf(), args);
        if (job == null) {
            return -1;
        }

        job.setInputFormatClass(SequenceFileInputFormat.class);
        job.setOutputKeyClass(IntWritable.class);
        job.setOutputFormatClass(SequenceFileOutputFormat.class);
        SequenceFileOutputFormat.setCompressOutput(job, true);
        SequenceFileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);
        SequenceFileOutputFormat.setOutputCompressionType(job, CompressionType.BLOCK);

        return job.waitForCompletion(true) ? 0 : 1;
    }

    public static void main(String[] args) throws Exception {
        int exitCode = ToolRunner.run(
                new SortByTemperatureUsingHashPartitioner(),
                args
        );
        System.exit(exitCode);
    }
}
```

키에 대한 정렬 순서는 RawComparator로 제어하며, 아래와 같이 설정한다.

-   mapreduce.job.output.key.comparator.class  속성을 설정 혹은 Job의 setSortComparatorClass()를 호출  
    \-> 해당 클래스의 객체 사용
-   위를 수행하지 않으면 키는 반드시 WritableComparable의 서브클래스여야 하며, 해당 키 클래스를 이용한 comparator 사용
-   등록된 비교자가 없다면 RawComparator 사용. (바이트 스트림을 객체로 역직렬화하여 compareTo()메서드에 위임)

#### 전체 정렬

하나의 파일이 아닌, 전체적으로 정렬된 파일을 생성하는 방법은? 

1\. 단일 파티션 사용 -> 단일 머신에서 모든 출력 처리? 비효율적.. 병렬 처리 이용 못함..

\=> 정렬된 파일 집합을 생성하고 병합! 전체 순서를 고려한 특정 파티셔닝을 사용하기!!

! 주의점 : ~(간단한 맵리듀스 잡을 통해 데이터 분포를 파악하고)~ 샘플링을 통해 각 파티션의 크기가 균등하도록 설정하자.

```
public interface Sampler<K, V> {
    K[] getSample(InputFormat<K, V> inf, Job job)
            throws IOException, InterruptedException;
}

public static <K, V> void writePartitionFile(Job job, Sampler<K, V> sampler)
        throws IOException, ClassNotFoundException, InterruptedException {
}

job.setPartitionerClass(TotalOrderPartitioner.class);

InputSampler.Sampler<IntWritable, Text> sampler =
        new InputSampler.RandomSampler<IntWritable, Text>(0.1, 10000, 10);
       // 인자 3개는 각각 샘플링 비율, 최대 샘플링 수, 맵 태스크 수이다.

InputSampler.writePartitionFile(job, sampler);
```

InputSampler는 위의 Sampler를 직접 호출하는 대신

writePartitionFile()을 통해 파티션의 키 범위를 담은 시퀀스 파일을 만들고,

TotalOrderPartitioner은 이 파일을 통해 파티션을 생성한다.

#### 2차 정렬

값을 기준으로도 정렬하고 싶어...! 

-   원래 키와 원래 값의 조합으로 새로운 키를 만든다.  
-   정렬 비교자는 조합 키(즉, 원래 키와 원래 값)를 기준으로 정렬한다. 
-   조합 키에 대한 파티셔너와 그룹화 비교자는 파티셔닝과 그룹화를 수행할 때 원래 키만 고려한다. 

예시를 들자면 아래와 같다.

-   **원래 키**: 연도(year)
-   **원래 값**: 온도(temperature)
-   **조합 키(Composite Key)**: (연도, 온도)처럼 **두 개를 합친 키**
-   **정렬 비교자(Sort Comparator)**: (연도, 온도) **둘 다** 보고 정렬
-   **파티셔너 / 그룹화 비교자(Grouping Comparator)**: **연도만** 보고 그룹화

"그룹화의 제어"

\=> 하나의 파티션 내에는 동일한 연도의 모든 레코드가 있으며, 내부적으로는 기온의 내림차순으로 정렬된다.

### Join

하이브,스파크와 같은 고차원 프레임워크를 활용하는것을 권장... 

[##_Image|kage@7Vsuv/btsPRgrF4yX/AAAAAAAAAAAAAAAAAAAAAO4fyVggeFUvrk8TYfjYd2aJIUKnKHlUyNr_GlKIqwqj/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=tsZaoUbEpCy1y1PCxIz0OMbL3tA%3D|CDM|1.3|{"originWidth":1093,"originHeight":993,"style":"alignCenter","width":368,"height":334,"caption":"두 데이터셋의 내부 조인"}_##]

데이터셋의 크기가 얼마나 큰가? 어떻게 분할되어 있는가?

위 2가지 질문에 따라 조인을 구현하는 방법은 달라질 수 있다. 

#### Map-Side Join

데이터가 맵 함수에 도달하기 전에 조인을 수행.  (매퍼에 의해)

각 입력 데이터셋은 동일한 개수의 파티션으로 분할되어야 하며, **동일한 조인키**로 정렬되어 있어야 함.

\-> 동일한 수의 리듀서,키, 분리되지 않는 출력 파일을 가진 여러 잡의 출력을 조인하는데 사용  
(주로 한쪽 데이터가 작을 때, 분산 캐시를 활용하여 사용)

org.apache.hadoop.mapreduce.join 패키지의 CompositeInputFormat을 사용 

#### Reduce-Side Join

map-side join과 달리 두 데이터셋 각각에 셔플 작업을 거친 후 조인을 진행. 

다만 동일한 조인키로 묶어주지 않아도 됨. 

"매퍼가 소스에 따라 각 레코드에 태그를 붙이고 조인키를 맵 출력키를 사용함으로써

동일한 키를 가진 레코드는 같은 리듀서에 모임"

### Distributed Cache

GenericOptionsParser에서 옵션을 통해 분산 캐시 기능을 활용할 수 있다.

[##_Image|kage@cifPz3/btsPNjJCkLU/AAAAAAAAAAAAAAAAAAAAAELCLrztuqo4SD_4vLVZLgOzXH6ZMVKBXCGQXI5oe9j5/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=Kmm1AbTyK7ypJSoWydsXSpA40r0%3D|CDM|1.3|{"originWidth":1108,"originHeight":861,"style":"floatLeft","width":479}_##]

실행 시점에 파일과 아카이브의 사본을 태스크 노드에 복사하여 이를 이용하도록 해주는 서비스. 

모든 파일에서 읽어올 수 있으며 default는 로컬. 

\-archives : 아카이브 파일 

\-libjars : JAR파일을 매퍼와 리듀서 태스크의 클래스패스에 추가

태스크 입장에서 파일은 그대로이고 심벌릭 링크가 존재하는것으로 볼 수 있다. 

<-  GenericOptionsParser를 사용하기 어려운 경우  
      Job의 API를 이용.

\*캐시의 공간 정책은 least-recently used를 사용하며,

yarn.nodemanager.localizer.cache.target-size-mb에서 캐시 크기를 조절할 수 있다.

### MapReduce Library Class

[##_Image|kage@cC1Ln3/btsPOD8M1n3/AAAAAAAAAAAAAAAAAAAAAJpNqD0sPYwU0lPqQB4LWO9HJbNCHOdWkz1hGBVU9Lsh/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&amp;expires=1756652399&amp;allow_ip=&amp;allow_referer=&amp;signature=1H1x1N9nm3RM8hJQjd%2FyXiAZk1w%3D|CDM|1.3|{"originWidth":1078,"originHeight":790,"style":"alignCenter","width":719,"height":527}_##]

---

 [신입개발자의 역량과 성장에 대해서(feat. Done is better than perfect) | 네이버페이 기술블로그

안녕하세요. 네이버 파이낸셜 카드 BE 팀의 허수진입니다. 저는 현재 3년차 서버 개발자로서 Java, Kot...

blog.naver.com](https://blog.naver.com/naverfinancial/223966743913)

좋은 글을 최근에 발견해서... 가져와 봤다.!

#### 컴파일 시점이란..?
